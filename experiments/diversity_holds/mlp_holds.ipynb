{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nimport sys\nimport os\nsys.path.append(os.path.join(os.path.dirname(os.getcwd()), '..'))\n\nimport torch\nfrom invertible_network_utils import construct_invertible_mlp\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom simclr.simclr import SimCLR\nfrom spaces import NSphereSpace\n\nfrom visualization_utils.spheres import visualize_spheres_side_by_side, scatter3d_sphere\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Create figures directory\nfigures_dir = Path('figures')\nfigures_dir.mkdir(exist_ok=True)\n\nprint('Using', device)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "sphere = NSphereSpace(3)\ng_mlp = construct_invertible_mlp(n=3, n_layers=3, act_fct=\"leaky_relu\")\n\nz = sphere.uniform(1000)\n\nprint('MAX NORM:',(g_mlp(z) ** 2).sum(dim=1).max())\n\nfig = visualize_spheres_side_by_side(plt, z, g_mlp(z))\nfig.savefig(figures_dir / 'mlp_data_generating_process.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from encoders import SphericalEncoder\n\ntau = 0.3\nkappa = 1 / tau\n\niterations = 10000\nbatch = 6144\n\nsample_pair_fixed = lambda batch: sphere.sample_pair_vmf(batch, kappa)\nsample_uniform_fixed = lambda batch: sphere.uniform(batch)\n\nf = SphericalEncoder()\n\nh = lambda z: f(g_mlp(z))\n\nz = sphere.uniform(1000)\nz_enc = h(z)\n\n# Before training visualization\nfig = visualize_spheres_side_by_side(plt, z, z_enc)\nfig.savefig(figures_dir / 'mlp_before_training_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nz = sphere.uniform(100000)\n\nfig = scatter3d_sphere(plt, z.cpu(), h(z.cpu()).cpu(), s=10, a=.8)\nfig.savefig(figures_dir / 'mlp_before_training_encoded.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nfig = scatter3d_sphere(plt, z.cpu(), z.cpu(), s=10, a=.8)\nfig.savefig(figures_dir / 'mlp_before_training_original.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from visualization_utils.scoring import plot_scores\nfrom experiment_utils.linear import linear_unrotation\n\nf = SphericalEncoder()\n\nsimclr_vmf = SimCLR(\n    f, g_mlp, sample_pair_fixed, sample_uniform_fixed, tau, device\n)\n\nf, scores = simclr_vmf.train(batch, iterations)\n\nh = lambda z: f(g_mlp(z))\n\nz = sphere.uniform(1000).to(device)\nz_enc = h(z).to(device)\n\nfig_scores = plot_scores(plt, scores)\nfig_scores.savefig(figures_dir / 'mlp_training_scores.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nfig = visualize_spheres_side_by_side(plt, z.cpu(), z_enc.cpu())\nfig.savefig(figures_dir / 'mlp_after_training_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nz = sphere.uniform(100000).to(device)\nz_enc = h(z)\n\nfig = scatter3d_sphere(plt, z.cpu(), z_enc.cpu(), s=10, a=.8)\nfig.savefig(figures_dir / 'mlp_after_training_encoded.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nfig = scatter3d_sphere(plt, z.cpu(), z.cpu(), s=10, a=.8)\nfig.savefig(figures_dir / 'mlp_after_training_original.png', dpi=150, bbox_inches='tight')\nplt.show()\n\n# Unrotation\nz_unrotated = linear_unrotation(z, z_enc)\nfig = scatter3d_sphere(plt, z.cpu(), z_unrotated, s=10, a=.8)\nfig.savefig(figures_dir / 'mlp_after_training_unrotated.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"All figures saved to {figures_dir}/\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}