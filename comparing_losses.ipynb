{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing InfoNCE and Adjusted InfoNCE Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class InfoNceLoss(torch.nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(InfoNceLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_recovered, z_sim_recovered, z_neg_recovered):\n",
    "        # Compute the dot products between each z and each \"negative\" sample\n",
    "        neg = torch.einsum(\"ij,kj -> ik\", z_recovered, z_neg_recovered)\n",
    "\n",
    "        # Compute the dot product between each z and recovered (positive sample)\n",
    "        pos = torch.einsum(\"ij,ij -> i\", z_recovered, z_sim_recovered)\n",
    "\n",
    "        neg_and_pos = torch.cat((neg, pos.unsqueeze(1)), dim=1)\n",
    "\n",
    "        loss_pos = -pos / self.temperature\n",
    "        loss_neg = torch.logsumexp(neg_and_pos / self.temperature, dim=1)\n",
    "        \n",
    "        total_loss = (loss_pos + loss_neg).mean()\n",
    "        \n",
    "        # Split for monitoring\n",
    "        pos_component = loss_pos.mean()\n",
    "        neg_component = loss_neg.mean()\n",
    "\n",
    "        return pos_component.detach().item(), neg_component.detach().item(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoNceLossAdjusted(torch.nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(InfoNceLossAdjusted, self).__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, z_recovered, z_enc_sim, z_enc_neg):\n",
    "        \"\"\"\n",
    "        Standard InfoNCE formulation: -log(exp(pos/τ) / (exp(pos/τ) + Σexp(neg/τ)))\n",
    "        \"\"\"\n",
    "        # Positive similarity\n",
    "        pos_sim = (z_recovered * z_enc_sim).sum(dim=-1) / self.temperature  # [N]\n",
    "        \n",
    "        # Negative similarities  \n",
    "        neg_sim = (z_recovered.unsqueeze(1) * z_enc_neg).sum(dim=-1) / self.temperature  # [N, M]\n",
    "        neg_sim_exp_sum = torch.exp(neg_sim).sum(dim=-1)\n",
    "        neg_sim_log = torch.log(neg_sim_exp_sum + torch.exp(pos_sim))\n",
    "        \n",
    "        loss = -pos_sim + neg_sim_log\n",
    "        \n",
    "        # Split for monitoring\n",
    "        pos_component = -pos_sim.mean()\n",
    "        neg_component = neg_sim_log.mean()\n",
    "        total_loss = loss.mean()\n",
    "        \n",
    "        return pos_component.detach().item(), neg_component.detach().item(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 7.836532115936279\n",
      "Adjusted: 7.836532115936279\n",
      "Orhtogonal: 7.800528526306152\n",
      "tensor([-0.1155,  0.1294,  0.9848])\n",
      "tensor([ 0.6504, -0.5285, -0.5456])\n",
      "tensor([-0.9113, -0.1109, -0.3966])\n"
     ]
    }
   ],
   "source": [
    "from spaces import NSphereSpace\n",
    "\n",
    "\n",
    "def compute_orthogonal_transformation_loss(tau, kappa, sample_pair, batch_size, latent_dim=3):\n",
    "        z, z_aug = sample_pair(batch_size, kappa)\n",
    "\n",
    "        z_neg = torch.nn.functional.normalize(\n",
    "            torch.randn((batch_size, batch_size, latent_dim), device=z.device), p=2, dim=-1\n",
    "        )\n",
    "\n",
    "        pos = - torch.sum(z * z_aug, dim=-1).mean() / tau\n",
    "        neg = torch.log(torch.exp((z.unsqueeze(1) * z_neg).sum(dim=-1) / tau).sum(-1)).mean()\n",
    "\n",
    "        return (pos + neg).item()\n",
    "\n",
    "tau = 0.3\n",
    "kapp = 1 / tau\n",
    "\n",
    "full_sphere = NSphereSpace(3)\n",
    "sub_sphere = NSphereSpace(2)\n",
    "\n",
    "normal_loss = InfoNceLoss(tau)\n",
    "adjusted_loss = InfoNceLossAdjusted(tau)\n",
    "\n",
    "batch = 6144\n",
    "\n",
    "z = full_sphere.uniform(batch)\n",
    "z, z_sim = full_sphere.sample_pair_vmf(batch, kapp)\n",
    "z_neg = full_sphere.uniform(batch)\n",
    "\n",
    "print(\"Normal:\", normal_loss(z, z_sim, z_neg)[2].item())\n",
    "z_neg_expanded = z_neg.unsqueeze(0).expand(z_neg.shape[0], -1, -1)  # Shape: (N, N, d)\n",
    "\n",
    "print(\"Adjusted:\", adjusted_loss(z, z_sim, z_neg_expanded)[2].item())\n",
    "print(\"Orhtogonal:\", compute_orthogonal_transformation_loss(tau, kapp, full_sphere.sample_pair_vmf, batch))\n",
    "\n",
    "print(z_neg_expanded[0,0])\n",
    "print(z_neg_expanded[0,1])\n",
    "print(z_neg_expanded[0,2])\n",
    "\n",
    "# print(adjusted_loss(z, z_sim, z_neg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
